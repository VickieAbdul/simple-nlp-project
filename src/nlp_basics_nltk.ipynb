{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dRZDo1RruMa"
      },
      "source": [
        "**Text Preprocessing & Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbCKX5mZqxyJ"
      },
      "outputs": [],
      "source": [
        "text = \"Machine learning is transforming the world of data science. It helps in making accurate predictions and decisions.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9XkJ2HQsCMS"
      },
      "source": [
        "**Tasks:**\n",
        "\n",
        "1. Tokenization:\n",
        "- Break the text into individual words.\n",
        "\n",
        "2. Stop Word Removal:\n",
        "- Remove common stop words.\n",
        "\n",
        "3. Stemming:\n",
        "- Apply PorterStemmer to the filtered tokens.\n",
        "\n",
        "4. Frequency Distribution:\n",
        "- Count how many times each word appears after stemming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn5ydMlfswLH"
      },
      "source": [
        "1. **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6X_1i58_r8q6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LQ65J1Wyvq8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e3839a-1fd3-4281-d884-56ad370f9729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        " nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gkqP-V_kt4dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20451f2-a922-4909-8303-fd57b589cd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word tokens are: ['Machine', 'learning', 'is', 'transforming', 'the', 'world', 'of', 'data', 'science', '.', 'It', 'helps', 'in', 'making', 'accurate', 'predictions', 'and', 'decisions', '.']\n"
          ]
        }
      ],
      "source": [
        "word_tokens = word_tokenize(text)\n",
        "print('The word tokens are:', word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zdV9Vcrkv2At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34dea57-66de-46d4-aeac-c467bb9fec7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence tokens are: ['Machine learning is transforming the world of data science.', 'It helps in making accurate predictions and decisions.']\n"
          ]
        }
      ],
      "source": [
        "sentence_tokens = sent_tokenize(text)\n",
        "print('The sentence tokens are:', sentence_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3sgCZxIwBgn"
      },
      "source": [
        "2. **Stopword Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JM5bGcKmwFtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3ba629-212e-4880-b3b4-28f085507000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zlH5v2uXwT8o"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_3zdcDoPwmZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46746e54-85a9-4aba-f8b5-1477aed22b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The filtered words are: ['Machine', 'learning', 'transforming', 'world', 'data', 'science', '.', 'helps', 'making', 'accurate', 'predictions', 'decisions', '.']\n"
          ]
        }
      ],
      "source": [
        "filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "print('The filtered words are:', filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqqFupVxKqB"
      },
      "source": [
        "3. **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k-641yVLxNWI"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "14K4TZu8xTIK"
      },
      "outputs": [],
      "source": [
        "# instantiate the stemmer object\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dNyGKwRUxoFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f45ac5-d729-465e-d2ba-2d27799e7fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The stemmed tokens are: ['machin', 'learn', 'transform', 'world', 'data', 'scienc', '.', 'help', 'make', 'accur', 'predict', 'decis', '.']\n"
          ]
        }
      ],
      "source": [
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_words]\n",
        "print('The stemmed tokens are:', stemmed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The words have been stemmed but the base text really do not make sense.\n",
        "\n",
        "Let's try nltk's lemmatization and see if we will have more meaningful base words."
      ],
      "metadata": {
        "id": "t4dFshCOSfbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Hff2xZ-OQLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c8b5f8-2ab6-4dbd-c91f-fe3fdefccee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JxQWToZ8zvWC"
      },
      "outputs": [],
      "source": [
        "# instantiate the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i1I4g-mRz5eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61080b89-9449-4678-f8c8-6cb4d4068108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lemmatized words are: ['Machine', 'learning', 'transforming', 'world', 'data', 'science', '.', 'help', 'making', 'accurate', 'prediction', 'decision', '.']\n"
          ]
        }
      ],
      "source": [
        " lem_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        " print('The lemmatized words are:', lem_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Rrg2bYysXl"
      },
      "source": [
        "We can see that nltk's lemmatizer has helped improve the base words but we can do better.\n",
        "\n",
        "This is where Spacy's lemmatization comes in to give the base words more meaning.\n",
        "\n",
        "We will explore this in another lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo7TzWhh0oGx"
      },
      "source": [
        "4. **Frequency Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CSkPeHfO0tIw"
      },
      "outputs": [],
      "source": [
        "# count how many times each word appears after stemming\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ytWtbHXs06Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cd870a-c44f-4cb9-8201-00f2ac5ec63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word frequency is: Counter({'.': 2, 'Machine': 1, 'learning': 1, 'transforming': 1, 'world': 1, 'data': 1, 'science': 1, 'help': 1, 'making': 1, 'accurate': 1, 'prediction': 1, 'decision': 1})\n"
          ]
        }
      ],
      "source": [
        "word_freq = Counter(lem_words)\n",
        "print('The word frequency is:', word_freq)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}